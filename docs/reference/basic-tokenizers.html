<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Basic tokenizers — basic-tokenizers • tokenizers</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>
  
  
<meta property="og:title" content="Basic tokenizers — basic-tokenizers" />

<meta property="og:description" content="These functions perform basic tokenization into words, sentences, paragraphs,
lines, and characters. The functions can be piped into one another to create
at most two levels of tokenization. For instance, one might split a text into
paragraphs and then word tokens, or into sentences and then word tokens." />
<meta name="twitter:card" content="summary" />
<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">tokenizers</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/introduction-to-tokenizers.html">Introduction to the tokenizers Package</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/ropensci/tokenizers">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Basic tokenizers</h1>
    </div>

    
    <p>These functions perform basic tokenization into words, sentences, paragraphs,
lines, and characters. The functions can be piped into one another to create
at most two levels of tokenization. For instance, one might split a text into
paragraphs and then word tokens, or into sentences and then word tokens.</p>
    

    <pre class="usage"><span class='fu'>tokenize_characters</span>(<span class='no'>x</span>, <span class='kw'>lowercase</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>strip_non_alphanum</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>simplify</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)

<span class='fu'>tokenize_words</span>(<span class='no'>x</span>, <span class='kw'>lowercase</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>stopwords</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>strip_punct</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>strip_numeric</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>simplify</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)

<span class='fu'>tokenize_sentences</span>(<span class='no'>x</span>, <span class='kw'>lowercase</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>strip_punct</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>simplify</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)

<span class='fu'>tokenize_lines</span>(<span class='no'>x</span>, <span class='kw'>simplify</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)

<span class='fu'>tokenize_paragraphs</span>(<span class='no'>x</span>, <span class='kw'>paragraph_break</span> <span class='kw'>=</span> <span class='st'>"\n\n"</span>, <span class='kw'>simplify</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)

<span class='fu'>tokenize_regex</span>(<span class='no'>x</span>, <span class='kw'>pattern</span> <span class='kw'>=</span> <span class='st'>"\\s+"</span>, <span class='kw'>simplify</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)

<span class='fu'>tokenize_tweets</span>(<span class='no'>x</span>, <span class='kw'>lowercase</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>stopwords</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>strip_punct</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>strip_url</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>simplify</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x</th>
      <td><p>A character vector or a list of character vectors to be tokenized
into n-grams. If <code>x</code> is a character vector, it can be of any length,
and each element will be tokenized separately. If <code>x</code> is a list of
character vectors, where each element of the list should have a length of
1.</p></td>
    </tr>
    <tr>
      <th>lowercase</th>
      <td><p>Should the tokens be made lower case? The default value
varies by tokenizer; it is only <code>TRUE</code> by default for the tokenizers
that you are likely to use last.</p></td>
    </tr>
    <tr>
      <th>strip_non_alphanum</th>
      <td><p>Should punctuation and white space be stripped?</p></td>
    </tr>
    <tr>
      <th>simplify</th>
      <td><p><code>FALSE</code> by default so that a consistent value is
returned regardless of length of input. If <code>TRUE</code>, then an input with
a single element will return a character vector of tokens instead of a
list.</p></td>
    </tr>
    <tr>
      <th>stopwords</th>
      <td><p>A character vector of stop words to be excluded.</p></td>
    </tr>
    <tr>
      <th>strip_punct</th>
      <td><p>Should punctuation be stripped?</p></td>
    </tr>
    <tr>
      <th>strip_numeric</th>
      <td><p>Should numbers be stripped?</p></td>
    </tr>
    <tr>
      <th>paragraph_break</th>
      <td><p>A string identifying the boundary between two
paragraphs.</p></td>
    </tr>
    <tr>
      <th>pattern</th>
      <td><p>A regular expression that defines the split.</p></td>
    </tr>
    <tr>
      <th>strip_url</th>
      <td><p>Should URLs (starting with http(s)) be preserved intact, or
removed entirely?</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A list of character vectors containing the tokens, with one element
  in the list for each element that was passed as input. If <code>simplify =
  TRUE</code> and only a single element was passed as input, then the output is a
  character vector of tokens.</p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='no'>song</span> <span class='kw'>&lt;-</span>  <span class='fu'>paste0</span>(<span class='st'>"How many roads must a man walk down\n"</span>,
                <span class='st'>"Before you call him a man?\n"</span>,
                <span class='st'>"How many seas must a white dove sail\n"</span>,
                <span class='st'>"Before she sleeps in the sand?\n"</span>,
                <span class='st'>"\n"</span>,
                <span class='st'>"How many times must the cannonballs fly\n"</span>,
                <span class='st'>"Before they're forever banned?\n"</span>,
                <span class='st'>"The answer, my friend, is blowin' in the wind.\n"</span>,
                <span class='st'>"The answer is blowin' in the wind.\n"</span>)

<span class='fu'>tokenize_words</span>(<span class='no'>song</span>)</div><div class='output co'>#&gt; [[1]]
#&gt;  [1] "how"    "many"   "roads"  "must"   "a"      "man"    "walk"   "down"  
#&gt;  [9] "before" "you"    "call"   "him"    "a"      "man"    "how"    "many"  
#&gt; [17] "seas"   "must"   "a"      "white"  "dove"   "sail"   "before" "she"   
#&gt; [25] "sleeps"
#&gt;  [ reached getOption("max.print") -- omitted 30 entries ]
#&gt; </div><div class='input'><span class='fu'>tokenize_words</span>(<span class='no'>song</span>, <span class='kw'>strip_punct</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</div><div class='output co'>#&gt; [[1]]
#&gt;  [1] "how"    "many"   "roads"  "must"   "a"      "man"    "walk"   "down"  
#&gt;  [9] "before" "you"    "call"   "him"    "a"      "man"    "?"      "how"   
#&gt; [17] "many"   "seas"   "must"   "a"      "white"  "dove"   "sail"   "before"
#&gt; [25] "she"   
#&gt;  [ reached getOption("max.print") -- omitted 39 entries ]
#&gt; </div><div class='input'><span class='fu'>tokenize_sentences</span>(<span class='no'>song</span>)</div><div class='output co'>#&gt; [[1]]
#&gt; [1] "How many roads must a man walk down Before you call him a man?"        
#&gt; [2] "How many seas must a white dove sail Before she sleeps in the sand?"   
#&gt; [3] "How many times must the cannonballs fly Before they're forever banned?"
#&gt; [4] "The answer, my friend, is blowin' in the wind."                        
#&gt; [5] "The answer is blowin' in the wind."                                    
#&gt; </div><div class='input'><span class='fu'>tokenize_paragraphs</span>(<span class='no'>song</span>)</div><div class='output co'>#&gt; [[1]]
#&gt; [1] "How many roads must a man walk down Before you call him a man? How many seas must a white dove sail Before she sleeps in the sand?"                       
#&gt; [2] "How many times must the cannonballs fly Before they're forever banned? The answer, my friend, is blowin' in the wind. The answer is blowin' in the wind. "
#&gt; </div><div class='input'><span class='fu'>tokenize_lines</span>(<span class='no'>song</span>)</div><div class='output co'>#&gt; [[1]]
#&gt; [1] "How many roads must a man walk down"           
#&gt; [2] "Before you call him a man?"                    
#&gt; [3] "How many seas must a white dove sail"          
#&gt; [4] "Before she sleeps in the sand?"                
#&gt; [5] "How many times must the cannonballs fly"       
#&gt; [6] "Before they're forever banned?"                
#&gt; [7] "The answer, my friend, is blowin' in the wind."
#&gt; [8] "The answer is blowin' in the wind."            
#&gt; </div><div class='input'><span class='fu'>tokenize_characters</span>(<span class='no'>song</span>)</div><div class='output co'>#&gt; [[1]]
#&gt;  [1] "h" "o" "w" "m" "a" "n" "y" "r" "o" "a" "d" "s" "m" "u" "s" "t" "a" "m" "a"
#&gt; [20] "n" "w" "a" "l" "k" "d"
#&gt;  [ reached getOption("max.print") -- omitted 194 entries ]
#&gt; </div><div class='input'><span class='fu'>tokenize_tweets</span>(<span class='st'>"@rOpenSci and #rstats see: https://cran.r-project.org"</span>,
                <span class='kw'>strip_punct</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)</div><div class='output co'>#&gt; [[1]]
#&gt; [1] "@rOpenSci"                  "and"                       
#&gt; [3] "#rstats"                    "see"                       
#&gt; [5] "https://cran.r-project.org"
#&gt; </div><div class='input'><span class='fu'>tokenize_tweets</span>(<span class='st'>"@rOpenSci and #rstats see: https://cran.r-project.org"</span>,
                <span class='kw'>strip_punct</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</div><div class='output co'>#&gt; [[1]]
#&gt; [1] "@rOpenSci"                  "and"                       
#&gt; [3] "#rstats"                    "see"                       
#&gt; [5] ":"                          "https://cran.r-project.org"
#&gt; </div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Lincoln Mullen.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>

