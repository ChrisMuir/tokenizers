<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Penn Treebank Tokenizer — tokenize_ptb • tokenizers</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>
<meta property="og:title" content="Penn Treebank Tokenizer — tokenize_ptb" />

<meta property="og:description" content="This function implements the Penn Treebank word tokenizer." />
<meta name="twitter:card" content="summary" />
<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">tokenizers</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/introduction-to-tokenizers.html">Introduction to the tokenizers Package</a>
    </li>
    <li>
      <a href="../articles/tif-and-tokenizers.html">The Text Interchange Formats and the tokenizers Package</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/ropensci/tokenizers">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Penn Treebank Tokenizer</h1>
    <small>Source: <a href='https:/github.com/ropensci/tokenizers/blob/master/R/ptb-tokenizer.R'><code>R/ptb-tokenizer.R</code></a></small>
    </div>

    
    <p>This function implements the Penn Treebank word tokenizer.</p>
    

    <pre class="usage"><span class='fu'>tokenize_ptb</span>(<span class='no'>x</span>, <span class='kw'>lowercase</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>simplify</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x</th>
      <td><p>A character vector or a list of character vectors to be tokenized
into n-grams. If <code>x</code> is a character vector, it can be of any length,
and each element will be tokenized separately. If <code>x</code> is a list of
character vectors, each element of the list should have a length of 1.</p></td>
    </tr>
    <tr>
      <th>lowercase</th>
      <td><p>Should the tokens be made lower case?</p></td>
    </tr>
    <tr>
      <th>simplify</th>
      <td><p><code>FALSE</code> by default so that a consistent value is
returned regardless of length of input. If <code>TRUE</code>, then an input with
a single element will return a character vector of tokens instead of a
list.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A list of character vectors containing the tokens, with one element
  in the list for each element that was passed as input. If <code>simplify =
  TRUE</code> and only a single element was passed as input, then the output is a
  character vector of tokens.</p>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>This tokenizer uses regular expressions to tokenize text similar to
  the tokenization used in the Penn Treebank. It assumes that text has
  already been split into sentences. The tokenizer does the following:</p>
<p></p><ul>
<li><p>splits common English contractions, e.g. <code>don't</code> is
  tokenized into <code>do n't</code> and <code>they'll</code> is tokenized into -&gt;
  <code>they 'll</code>,</p></li>
<li><p>handles punctuation characters as separate tokens,</p></li>
<li><p>splits commas and single quotes off from words, when they are
  followed by whitespace,</p></li>
<li><p>splits off periods that occur at the end of
  the sentence.</p></li>
</ul>
    <p>This function is a port of the Python NLTK version of the Penn
  Treebank Tokenizer.</p>
    
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p><a href='http://www.nltk.org/_modules/nltk/tokenize/treebank.html#TreebankWordTokenizer'>NLTK
TreebankWordTokenizer</a></p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='no'>song</span> <span class='kw'>&lt;-</span> <span class='fu'>list</span>(<span class='fu'>paste0</span>(<span class='st'>"How many roads must a man walk down\n"</span>,
                    <span class='st'>"Before you call him a man?"</span>),
             <span class='fu'>paste0</span>(<span class='st'>"How many seas must a white dove sail\n"</span>,
                    <span class='st'>"Before she sleeps in the sand?\n"</span>),
             <span class='fu'>paste0</span>(<span class='st'>"How many times must the cannonballs fly\n"</span>,
                    <span class='st'>"Before they're forever banned?\n"</span>),
             <span class='st'>"The answer, my friend, is blowin' in the wind."</span>,
             <span class='st'>"The answer is blowin' in the wind."</span>)
<span class='fu'>tokenize_ptb</span>(<span class='no'>song</span>)</div><div class='output co'>#&gt; [[1]]
#&gt;  [1] "How"    "many"   "roads"  "must"   "a"      "man"    "walk"   "down"  
#&gt;  [9] "Before" "you"    "call"   "him"    "a"      "man"    "?"     
#&gt; 
#&gt; [[2]]
#&gt;  [1] "How"    "many"   "seas"   "must"   "a"      "white"  "dove"   "sail"  
#&gt;  [9] "Before" "she"    "sleeps" "in"     "the"    "sand"   "?"     
#&gt; 
#&gt; [[3]]
#&gt;  [1] "How"         "many"        "times"       "must"        "the"        
#&gt;  [6] "cannonballs" "fly"         "Before"      "they"        "'re"        
#&gt; [11] "forever"     "banned"      "?"          
#&gt; 
#&gt; [[4]]
#&gt;  [1] "The"    "answer" ","      "my"     "friend" ","      "is"     "blowin"
#&gt;  [9] "'"      "in"     "the"    "wind"   "."     
#&gt; 
#&gt; [[5]]
#&gt; [1] "The"    "answer" "is"     "blowin" "'"      "in"     "the"    "wind"  
#&gt; [9] "."     
#&gt; </div><div class='input'><span class='fu'>tokenize_ptb</span>(<span class='fu'>c</span>(<span class='st'>"Good muffins cost $3.88\nin New York. Please buy me\ntwo of them."</span>,
  <span class='st'>"They'll save and invest more."</span>,
  <span class='st'>"Hi, I can't say hello."</span>))</div><div class='output co'>#&gt; [[1]]
#&gt;  [1] "Good"    "muffins" "cost"    "$"       "3.88"    "in"      "New"    
#&gt;  [8] "York."   "Please"  "buy"     "me"      "two"     "of"      "them"   
#&gt; [15] "."      
#&gt; 
#&gt; [[2]]
#&gt; [1] "They"   "'ll"    "save"   "and"    "invest" "more"   "."     
#&gt; 
#&gt; [[3]]
#&gt; [1] "Hi"    ","     "I"     "ca"    "n't"   "say"   "hello" "."    
#&gt; </div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#details">Details</a></li>

      <li><a href="#references">References</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Lincoln Mullen.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>

