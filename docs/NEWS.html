<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>/Users/lmullen/dev/tokenizers/NEWS.md • tokenizers</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="pkgdown.css" rel="stylesheet">
<script src="jquery.sticky-kit.min.js"></script>
<script src="pkgdown.js"></script>
  
  
<meta property="og:title" content="/Users/lmullen/dev/tokenizers/NEWS.md" />
<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-title-body">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">tokenizers</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="articles/introduction-to-tokenizers.html">Introduction to the tokenizers Package</a>
    </li>
    <li>
      <a href="articles/tif-and-tokenizers.html">The Text Interchange Formats and the tokenizers Package</a>
    </li>
  </ul>
</li>
<li>
  <a href="news/index.html">News</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/ropensci/tokenizers">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="contents col-md-12">
    <div class="page-header">
      <h1>/Users/lmullen/dev/tokenizers/NEWS.md</h1>
    </div>


<div class="section level1">
<h1>tokenizers 0.2.0</h1>
<div class="section level2">
<h2>Features</h2>
<ul>
<li>Add the <code><a href="reference/ptb-tokenizer.html">tokenize_ptb()</a></code> function for Penn Treebank tokenizations (@jrnold) (#12).</li>
<li>Add a function <code><a href="reference/chunk_text.html">chunk_text()</a></code> to split long documents into pieces (#30).</li>
<li>New functions to count words, characters, and sentences without tokenization (#36).</li>
<li>New function <code><a href="reference/basic-tokenizers.html">tokenize_tweets()</a></code> preserves usernames, hashtags, and URLS (@kbenoit) (#44).</li>
<li>The <code>stopwords()</code> function has been removed in favor of using the stopwords package (#46).</li>
<li>The package now complies with the basic recommendations of the Text Interchange Format. All tokenization functions are now methods. This enables them to take corpus inputs as either TIF-compliant named character vectors, named lists, or data frames. All outputs are still named lists of tokens, but these can be easily coerced to data frames of tokens using the <code>tif</code> package. (#49)</li>
<li>Add a new vignette “The Text Interchange Formats and the tokenizers Package” (#49).</li>
</ul>
</div>
<div class="section level2">
<h2>Bug fixes and performance improvements</h2>
<ul>
<li>
<code>tokenize_skip_ngrams</code> has been improved to generate unigrams and bigrams, according to the skip definition (#24).</li>
<li>C++98 has replaced the C++11 code used for n-gram generation, widening the range of compilers <code>tokenizers</code> supports (#26).</li>
<li>
<code>tokenize_skip_ngrams</code> now supports stopwords (#31).</li>
<li>If tokenisers fail to generate tokens for a particular entry, they return <code>NA</code> consistently (#33).</li>
<li>Keyboard interrupt checks have been added to Rcpp-backed functions to enable users to terminate them before completion (#37).</li>
<li>
<code><a href="reference/basic-tokenizers.html">tokenize_words()</a></code> gains arguments to preserve or strip punctuation and numbers (#48).</li>
<li>
<code><a href="reference/ngram-tokenizers.html">tokenize_skip_ngrams()</a></code> and <code><a href="reference/ngram-tokenizers.html">tokenize_ngrams()</a></code> to return properly marked UTF8 strings on Windows (@patperry) (#58).</li>
</ul>
</div>
</div>
<div class="section level1">
<h1>tokenizers 0.1.4</h1>
<ul>
<li>Add the <code><a href="reference/shingle-tokenizers.html">tokenize_character_shingles()</a></code> tokenizer.</li>
<li>Improvements to documentation.</li>
</ul>
</div>
<div class="section level1">
<h1>tokenizers 0.1.3</h1>
<ul>
<li>Add vignette.</li>
<li>Improvements to n-gram tokenizers.</li>
</ul>
</div>
<div class="section level1">
<h1>tokenizers 0.1.2</h1>
<ul>
<li>Add stopwords for several languages.</li>
<li>New stopword options to <code><a href="reference/basic-tokenizers.html">tokenize_words()</a></code> and <code><a href="reference/stem-tokenizers.html">tokenize_word_stems()</a></code>.</li>
</ul>
</div>
<div class="section level1">
<h1>tokenizers 0.1.1</h1>
<ul>
<li>Fix failing test in non-UTF-8 locales.</li>
</ul>
</div>
<div class="section level1">
<h1>tokenizers 0.1.0</h1>
<ul>
<li>Initial release with tokenizers for characters, words, word stems, sentences paragraphs, n-grams, skip n-grams, lines, and regular expressions.</li>
</ul>
</div>


  </div>

</div>


      <footer>
      <div class="copyright">
  <p>Developed by Lincoln Mullen.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>

