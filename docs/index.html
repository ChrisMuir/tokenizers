<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>A Consistent Interface to Tokenize Natural Language Text â€¢ tokenizers</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- pkgdown --><link href="pkgdown.css" rel="stylesheet">
<script src="jquery.sticky-kit.min.js"></script><script src="pkgdown.js"></script><meta property="og:title" content="A Consistent Interface to Tokenize Natural Language Text">
<meta property="og:description" content="Convert natural language text into tokens. The tokenizers have a
    consistent interface and are compatible with Unicode, thanks to being built
    on the 'stringi' package. Includes tokenizers for shingled n-grams, skip
    n-grams, words, word stems, sentences, paragraphs, characters, shingled 
    characters, lines, tweets, Penn Treebank, regular expressions, as well
    as functions for counting characters, words, and sentences, and a function
    for splitting longer texts into separate documents, each with the same number
    of words.  The package is built on the 'stringi' and 'Rcpp' packages for 
    lightening fast yet correct tokenization in 'UTF-8'. ">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">tokenizers</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="articles/introduction-to-tokenizers.html">Introduction to the tokenizers Package</a>
    </li>
  </ul>
</li>
<li>
  <a href="news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/ropensci/tokenizers">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    

    
    
<div class="contents">
<!-- README.md is generated from README.Rmd. Please edit that file -->
<div id="tokenizers" class="section level1">
<div class="page-header"><h1 class="hasAnchor">
<a href="#tokenizers" class="anchor"></a>tokenizers</h1></div>

<div id="overview" class="section level2">
<h2 class="hasAnchor">
<a href="#overview" class="anchor"></a>Overview</h2>
<p>An R package offering functions with a consistent interface to convert natural language text into tokens. Includes tokenizers for shingled n-grams, skip n-grams, words, word stems, sentences, paragraphs, characters, shingled characters, lines, tweets, Penn Treebank, and regular expressions, as well as functions for counting characters, words, and sentences, and a function for splitting longer texts into separate documents, each with the same number of words. The package is built on the <a href="http://www.gagolewski.com/software/stringi/">stringi</a> and <a href="http://www.rcpp.org/">Rcpp</a> packages for lightening fast yet correct tokenization in UTF-8.</p>
</div>
<div id="installation" class="section level2">
<h2 class="hasAnchor">
<a href="#installation" class="anchor"></a>Installation</h2>
<p>You can install this package from CRAN:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">install.packages</span>(<span class="st">"tokenizers"</span>)</a></code></pre></div>
<p>To get the development version from GitHub, use <a href="https://github.com/hadley/devtools">devtools</a>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="co"># install.packages("devtools")</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2">devtools<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/install_github">install_github</a></span>(<span class="st">"ropensci/tokenizers"</span>)</a></code></pre></div>
</div>
<div id="examples" class="section level2">
<h2 class="hasAnchor">
<a href="#examples" class="anchor"></a>Examples</h2>
<p>The tokenizers in this package have a consistent interface. They all take either a character vector of any length, or a list where each element is a character vector of length one. The idea is that each element comprises a text. Then each function returns a list with the same length as the input vector, where each element in the list contains the tokens generated by the function. If the input character vector or list is named, then the names are preserved, so that the names can serve as identifiers.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="kw">library</span>(magrittr)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="kw">library</span>(tokenizers)</a>
<a class="sourceLine" id="cb3-3" data-line-number="3"></a>
<a class="sourceLine" id="cb3-4" data-line-number="4">james &lt;-<span class="st"> </span><span class="kw">paste0</span>(</a>
<a class="sourceLine" id="cb3-5" data-line-number="5">  <span class="st">"The question thus becomes a verbal one</span><span class="ch">\n</span><span class="st">"</span>,</a>
<a class="sourceLine" id="cb3-6" data-line-number="6">  <span class="st">"again; and our knowledge of all these early stages of thought and feeling</span><span class="ch">\n</span><span class="st">"</span>,</a>
<a class="sourceLine" id="cb3-7" data-line-number="7">  <span class="st">"is in any case so conjectural and imperfect that farther discussion would</span><span class="ch">\n</span><span class="st">"</span>,</a>
<a class="sourceLine" id="cb3-8" data-line-number="8">  <span class="st">"not be worth while.</span><span class="ch">\n</span><span class="st">"</span>,</a>
<a class="sourceLine" id="cb3-9" data-line-number="9">  <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>,</a>
<a class="sourceLine" id="cb3-10" data-line-number="10">  <span class="st">"Religion, therefore, as I now ask you arbitrarily to take it, shall mean</span><span class="ch">\n</span><span class="st">"</span>,</a>
<a class="sourceLine" id="cb3-11" data-line-number="11">  <span class="st">"for us _the feelings, acts, and experiences of individual men in their</span><span class="ch">\n</span><span class="st">"</span>,</a>
<a class="sourceLine" id="cb3-12" data-line-number="12">  <span class="st">"solitude, so far as they apprehend themselves to stand in relation to</span><span class="ch">\n</span><span class="st">"</span>,</a>
<a class="sourceLine" id="cb3-13" data-line-number="13">  <span class="st">"whatever they may consider the divine_. Since the relation may be either</span><span class="ch">\n</span><span class="st">"</span>,</a>
<a class="sourceLine" id="cb3-14" data-line-number="14">  <span class="st">"moral, physical, or ritual, it is evident that out of religion in the</span><span class="ch">\n</span><span class="st">"</span>,</a>
<a class="sourceLine" id="cb3-15" data-line-number="15">  <span class="st">"sense in which we take it, theologies, philosophies, and ecclesiastical</span><span class="ch">\n</span><span class="st">"</span>,</a>
<a class="sourceLine" id="cb3-16" data-line-number="16">  <span class="st">"organizations may secondarily grow.</span><span class="ch">\n</span><span class="st">"</span></a>
<a class="sourceLine" id="cb3-17" data-line-number="17">)</a>
<a class="sourceLine" id="cb3-18" data-line-number="18"><span class="kw">names</span>(james) &lt;-<span class="st"> "varieties"</span></a>
<a class="sourceLine" id="cb3-19" data-line-number="19"></a>
<a class="sourceLine" id="cb3-20" data-line-number="20"><span class="kw"><a href="reference/basic-tokenizers.html">tokenize_characters</a></span>(james)[[<span class="dv">1</span>]] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">50</span>)</a>
<a class="sourceLine" id="cb3-21" data-line-number="21"><span class="co">#&gt;  [1] "t" "h" "e" "q" "u" "e" "s" "t" "i" "o" "n" "t" "h" "u" "s" "b" "e"</span></a>
<a class="sourceLine" id="cb3-22" data-line-number="22"><span class="co">#&gt; [18] "c" "o" "m" "e" "s" "a" "v" "e" "r" "b" "a" "l" "o" "n" "e" "a" "g"</span></a>
<a class="sourceLine" id="cb3-23" data-line-number="23"><span class="co">#&gt; [35] "a" "i" "n" "a" "n" "d" "o" "u" "r" "k" "n" "o" "w" "l" "e" "d"</span></a>
<a class="sourceLine" id="cb3-24" data-line-number="24"><span class="kw"><a href="reference/shingle-tokenizers.html">tokenize_character_shingles</a></span>(james)[[<span class="dv">1</span>]] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">20</span>)</a>
<a class="sourceLine" id="cb3-25" data-line-number="25"><span class="co">#&gt;  [1] "the" "heq" "equ" "que" "ues" "est" "sti" "tio" "ion" "ont" "nth"</span></a>
<a class="sourceLine" id="cb3-26" data-line-number="26"><span class="co">#&gt; [12] "thu" "hus" "usb" "sbe" "bec" "eco" "com" "ome" "mes"</span></a>
<a class="sourceLine" id="cb3-27" data-line-number="27"><span class="kw"><a href="reference/basic-tokenizers.html">tokenize_words</a></span>(james)[[<span class="dv">1</span>]] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb3-28" data-line-number="28"><span class="co">#&gt;  [1] "the"      "question" "thus"     "becomes"  "a"        "verbal"  </span></a>
<a class="sourceLine" id="cb3-29" data-line-number="29"><span class="co">#&gt;  [7] "one"      "again"    "and"      "our"</span></a>
<a class="sourceLine" id="cb3-30" data-line-number="30"><span class="kw"><a href="reference/stem-tokenizers.html">tokenize_word_stems</a></span>(james)[[<span class="dv">1</span>]] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb3-31" data-line-number="31"><span class="co">#&gt;  [1] "the"      "question" "thus"     "becom"    "a"        "verbal"  </span></a>
<a class="sourceLine" id="cb3-32" data-line-number="32"><span class="co">#&gt;  [7] "one"      "again"    "and"      "our"</span></a>
<a class="sourceLine" id="cb3-33" data-line-number="33"><span class="kw"><a href="reference/basic-tokenizers.html">tokenize_sentences</a></span>(james) </a>
<a class="sourceLine" id="cb3-34" data-line-number="34"><span class="co">#&gt; $varieties</span></a>
<a class="sourceLine" id="cb3-35" data-line-number="35"><span class="co">#&gt; [1] "The question thus becomes a verbal one again; and our knowledge of all these early stages of thought and feeling is in any case so conjectural and imperfect that farther discussion would not be worth while."                                               </span></a>
<a class="sourceLine" id="cb3-36" data-line-number="36"><span class="co">#&gt; [2] "Religion, therefore, as I now ask you arbitrarily to take it, shall mean for us _the feelings, acts, and experiences of individual men in their solitude, so far as they apprehend themselves to stand in relation to whatever they may consider the divine_."</span></a>
<a class="sourceLine" id="cb3-37" data-line-number="37"><span class="co">#&gt; [3] "Since the relation may be either moral, physical, or ritual, it is evident that out of religion in the sense in which we take it, theologies, philosophies, and ecclesiastical organizations may secondarily grow."</span></a>
<a class="sourceLine" id="cb3-38" data-line-number="38"><span class="kw"><a href="reference/basic-tokenizers.html">tokenize_paragraphs</a></span>(james)</a>
<a class="sourceLine" id="cb3-39" data-line-number="39"><span class="co">#&gt; $varieties</span></a>
<a class="sourceLine" id="cb3-40" data-line-number="40"><span class="co">#&gt; [1] "The question thus becomes a verbal one again; and our knowledge of all these early stages of thought and feeling is in any case so conjectural and imperfect that farther discussion would not be worth while."                                                                                                                                                                                                                                                                   </span></a>
<a class="sourceLine" id="cb3-41" data-line-number="41"><span class="co">#&gt; [2] "Religion, therefore, as I now ask you arbitrarily to take it, shall mean for us _the feelings, acts, and experiences of individual men in their solitude, so far as they apprehend themselves to stand in relation to whatever they may consider the divine_. Since the relation may be either moral, physical, or ritual, it is evident that out of religion in the sense in which we take it, theologies, philosophies, and ecclesiastical organizations may secondarily grow. "</span></a>
<a class="sourceLine" id="cb3-42" data-line-number="42"><span class="kw"><a href="reference/ngram-tokenizers.html">tokenize_ngrams</a></span>(james, <span class="dt">n =</span> <span class="dv">5</span>, <span class="dt">n_min =</span> <span class="dv">2</span>)[[<span class="dv">1</span>]] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb3-43" data-line-number="43"><span class="co">#&gt;  [1] "the question"                   "the question thus"             </span></a>
<a class="sourceLine" id="cb3-44" data-line-number="44"><span class="co">#&gt;  [3] "the question thus becomes"      "the question thus becomes a"   </span></a>
<a class="sourceLine" id="cb3-45" data-line-number="45"><span class="co">#&gt;  [5] "question thus"                  "question thus becomes"         </span></a>
<a class="sourceLine" id="cb3-46" data-line-number="46"><span class="co">#&gt;  [7] "question thus becomes a"        "question thus becomes a verbal"</span></a>
<a class="sourceLine" id="cb3-47" data-line-number="47"><span class="co">#&gt;  [9] "thus becomes"                   "thus becomes a"</span></a>
<a class="sourceLine" id="cb3-48" data-line-number="48"><span class="kw"><a href="reference/ngram-tokenizers.html">tokenize_skip_ngrams</a></span>(james, <span class="dt">n =</span> <span class="dv">5</span>, <span class="dt">k =</span> <span class="dv">2</span>)[[<span class="dv">1</span>]] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb3-49" data-line-number="49"><span class="co">#&gt;  [1] "the"                  "the question"         "the thus"            </span></a>
<a class="sourceLine" id="cb3-50" data-line-number="50"><span class="co">#&gt;  [4] "the becomes"          "the question thus"    "the question becomes"</span></a>
<a class="sourceLine" id="cb3-51" data-line-number="51"><span class="co">#&gt;  [7] "the question a"       "the thus becomes"     "the thus a"          </span></a>
<a class="sourceLine" id="cb3-52" data-line-number="52"><span class="co">#&gt; [10] "the thus verbal"</span></a>
<a class="sourceLine" id="cb3-53" data-line-number="53"><span class="kw"><a href="reference/ptb-tokenizer.html">tokenize_ptb</a></span>(james)[[<span class="dv">1</span>]] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb3-54" data-line-number="54"><span class="co">#&gt;  [1] "The"      "question" "thus"     "becomes"  "a"        "verbal"  </span></a>
<a class="sourceLine" id="cb3-55" data-line-number="55"><span class="co">#&gt;  [7] "one"      "again"    ";"        "and"</span></a>
<a class="sourceLine" id="cb3-56" data-line-number="56"><span class="kw"><a href="reference/basic-tokenizers.html">tokenize_lines</a></span>(james)[[<span class="dv">1</span>]] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">5</span>)</a>
<a class="sourceLine" id="cb3-57" data-line-number="57"><span class="co">#&gt; [1] "The question thus becomes a verbal one"                                   </span></a>
<a class="sourceLine" id="cb3-58" data-line-number="58"><span class="co">#&gt; [2] "again; and our knowledge of all these early stages of thought and feeling"</span></a>
<a class="sourceLine" id="cb3-59" data-line-number="59"><span class="co">#&gt; [3] "is in any case so conjectural and imperfect that farther discussion would"</span></a>
<a class="sourceLine" id="cb3-60" data-line-number="60"><span class="co">#&gt; [4] "not be worth while."                                                      </span></a>
<a class="sourceLine" id="cb3-61" data-line-number="61"><span class="co">#&gt; [5] "Religion, therefore, as I now ask you arbitrarily to take it, shall mean"</span></a>
<a class="sourceLine" id="cb3-62" data-line-number="62"><span class="kw"><a href="reference/basic-tokenizers.html">tokenize_tweets</a></span>(<span class="st">"Hey @handle, #rstats is awesome!"</span>)[[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb3-63" data-line-number="63"><span class="co">#&gt; [1] "hey"     "@handle" "#rstats" "is"      "awesome"</span></a></code></pre></div>
<p>The package also contains functions to count words, characters, and sentences, and these functions follow the same consistent interface.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw"><a href="reference/word-counting.html">count_words</a></span>(james)</a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="co">#&gt; varieties </span></a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="co">#&gt;       112</span></a>
<a class="sourceLine" id="cb4-4" data-line-number="4"><span class="kw"><a href="reference/word-counting.html">count_characters</a></span>(james)</a>
<a class="sourceLine" id="cb4-5" data-line-number="5"><span class="co">#&gt; varieties </span></a>
<a class="sourceLine" id="cb4-6" data-line-number="6"><span class="co">#&gt;       673</span></a>
<a class="sourceLine" id="cb4-7" data-line-number="7"><span class="kw"><a href="reference/word-counting.html">count_sentences</a></span>(james)</a>
<a class="sourceLine" id="cb4-8" data-line-number="8"><span class="co">#&gt; varieties </span></a>
<a class="sourceLine" id="cb4-9" data-line-number="9"><span class="co">#&gt;        13</span></a></code></pre></div>
<p>The <code><a href="reference/chunk_text.html">chunk_text()</a></code> function splits a document into smaller chunks, each with the same number of words.</p>
</div>
<div id="contributing" class="section level2">
<h2 class="hasAnchor">
<a href="#contributing" class="anchor"></a>Contributing</h2>
<p>Contributions to the package are more than welcome. One way that you can help is by using this package in your R package for natural language processing. If you want to contribute a tokenization function to this package, it should follow the same conventions as the rest of the functions whenever it makes sense to do so.</p>
<p>Please note that this project is released with a <a href="CONDUCT.md">Contributor Code of Conduct</a>. By participating in this project you agree to abide by its terms.</p>
<hr>
<p><a href="http://ropensci.org"><img src="http://ropensci.org/public_images/github_footer.png" alt="rOpenSCi logo"></a></p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2 class="hasAnchor">
<a href="#sidebar" class="anchor"></a>Links</h2>
<ul class="list-unstyled">
<li>Download from CRAN at <br><a href="https://cran.r-project.org/package=tokenizers">https://â€‹cran.r-project.org/â€‹package=tokenizers</a>
</li>
<li>Browse source code at <br><a href="https://github.com/ropensci/tokenizers">https://â€‹github.com/â€‹ropensci/â€‹tokenizers</a>
</li>
<li>Report a bug at <br><a href="https://github.com/ropensci/tokenizers/issues">https://â€‹github.com/â€‹ropensci/â€‹tokenizers/â€‹issues</a>
</li>
</ul>
<h2>License</h2>
<p><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file <a href="LICENSE.html">LICENSE</a></p>
<h2>Developers</h2>
<ul class="list-unstyled">
<li>Lincoln Mullen <br><small class="roles"> Author, maintainer </small> <a href="https://orcid.org/0000-0001-5103-6917" target="orcid.widget"><img src="https://members.orcid.org/sites/default/files/vector_iD_icon.svg" class="orcid"></a> </li>
<li><a href="authors.html">All authors...</a></li>
</ul>
<h2>Dev status</h2>
<ul class="list-unstyled">
<li><a href="http://cran.r-project.org/package=tokenizers"><img src="http://www.r-pkg.org/badges/version/tokenizers" alt="CRAN_Status_Badge"></a></li>
<li><a href="http://cran.r-project.org/package=tokenizers"><img src="http://cranlogs.r-pkg.org/badges/grand-total/tokenizers" alt="CRAN_Downloads"></a></li>
<li><a href="https://travis-ci.org/ropensci/tokenizers"><img src="https://travis-ci.org/ropensci/tokenizers.svg?branch=master" alt="Travis-CI Build Status"></a></li>
<li><a href="https://ci.appveyor.com/project/lmullen/tokenizers-dkf3v/branch/master"><img src="https://ci.appveyor.com/api/projects/status/qx3vh3ukjgo99iu4/branch/master?svg=true" alt="Appveyor Build status"></a></li>
<li><a href="https://codecov.io/github/ropensci/tokenizers?branch=master"><img src="https://img.shields.io/codecov/c/github/ropensci/tokenizers/master.svg" alt="Coverage Status"></a></li>
<li><a href="https://github.com/ropensci/onboarding/issues/33"><img src="https://badges.ropensci.org/33_status.svg"></a></li>
</ul>
</div>

</div>


      <footer><div class="copyright">
  <p>Developed by Lincoln Mullen.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
